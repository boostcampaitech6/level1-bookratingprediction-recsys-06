{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /data/ephemeral/home/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import wandb\n",
    "wandb.login(key = 'personal key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: main.py [-h] [--data_path DATA_PATH]\n",
      "               [--saved_model_path SAVED_MODEL_PATH]\n",
      "               [--model {FM,FFM,NCF,WDN,SDCN,PDCN,CNN_FM,DeepCoNN}]\n",
      "               [--data_shuffle DATA_SHUFFLE] [--test_size TEST_SIZE]\n",
      "               [--seed SEED] [--use_best_model USE_BEST_MODEL]\n",
      "               [--patience PATIENCE] [--runname RUNNAME]\n",
      "               [--batch_size BATCH_SIZE] [--epochs EPOCHS] [--lr LR]\n",
      "               [--loss_fn {MSE,RMSE}]\n",
      "               [--optimizer {SGD,Adam,AdamW,NAdam,SparseAdam}]\n",
      "               [--weight_decay WEIGHT_DECAY]\n",
      "               [--lr_scheduler {LAMBDA,Multiplicative,Step,MultiStep,Exponential,CosineAnnealing,Cyclic_triangular,Cyclic_triangular2,OneCycle_cos,OneCycle_linear,CosineAnnealingWarmRestarts}]\n",
      "               [--device {cuda,cpu}] [--embed_dim EMBED_DIM]\n",
      "               [--dropout DROPOUT] [--mlp_dims MLP_DIMS]\n",
      "               [--num_layers NUM_LAYERS] [--cnn_embed_dim CNN_EMBED_DIM]\n",
      "               [--cnn_latent_dim CNN_LATENT_DIM]\n",
      "               [--vector_create VECTOR_CREATE]\n",
      "               [--deepconn_embed_dim DEEPCONN_EMBED_DIM]\n",
      "               [--deepconn_latent_dim DEEPCONN_LATENT_DIM]\n",
      "               [--conv_1d_out_dim CONV_1D_OUT_DIM] [--kernel_size KERNEL_SIZE]\n",
      "               [--word_dim WORD_DIM] [--out_dim OUT_DIM]\n",
      "\n",
      "parser\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --data_path DATA_PATH\n",
      "                        Data path를 설정할 수 있습니다.\n",
      "  --saved_model_path SAVED_MODEL_PATH\n",
      "                        Saved Model path를 설정할 수 있습니다.\n",
      "  --model {FM,FFM,NCF,WDN,SDCN,PDCN,CNN_FM,DeepCoNN}\n",
      "                        학습 및 예측할 모델을 선택할 수 있습니다.\n",
      "  --data_shuffle DATA_SHUFFLE\n",
      "                        데이터 셔플 여부를 조정할 수 있습니다.\n",
      "  --test_size TEST_SIZE\n",
      "                        Train/Valid split 비율을 조정할 수 있습니다.\n",
      "  --seed SEED           seed 값을 조정할 수 있습니다.\n",
      "  --use_best_model USE_BEST_MODEL\n",
      "                        검증 성능이 가장 좋은 모델 사용여부를 설정할 수 있습니다.\n",
      "  --patience PATIENCE   Earlystop의 patience를 설정할 수 있습니다.\n",
      "  --runname RUNNAME     모델과 파라티머의 정보를 간략하게 적어 내용을 저장할 수 있습니다.\n",
      "  --batch_size BATCH_SIZE\n",
      "                        Batch size를 조정할 수 있습니다.\n",
      "  --epochs EPOCHS       Epoch 수를 조정할 수 있습니다.\n",
      "  --lr LR               Learning Rate를 조정할 수 있습니다.\n",
      "  --loss_fn {MSE,RMSE}  손실 함수를 변경할 수 있습니다.\n",
      "  --optimizer {SGD,Adam,AdamW,NAdam,SparseAdam}\n",
      "                        최적화 함수를 변경할 수 있습니다.\n",
      "  --weight_decay WEIGHT_DECAY\n",
      "                        Adam optimizer에서 정규화에 사용하는 값을 조정할 수 있습니다.\n",
      "  --lr_scheduler {LAMBDA,Multiplicative,Step,MultiStep,Exponential,CosineAnnealing,Cyclic_triangular,Cyclic_triangular2,OneCycle_cos,OneCycle_linear,CosineAnnealingWarmRestarts}\n",
      "                        Learning Rate Scheduler를 사용할 수 있습니다.\n",
      "  --device {cuda,cpu}   학습에 사용할 Device를 조정할 수 있습니다.\n",
      "  --embed_dim EMBED_DIM\n",
      "                        FM, FFM, NCF, WDN, DCN에서 embedding시킬 차원을 조정할 수 있습니다.\n",
      "  --dropout DROPOUT     NCF, WDN, DCN에서 Dropout rate를 조정할 수 있습니다.\n",
      "  --mlp_dims MLP_DIMS   NCF, WDN, DCN에서 MLP Network의 차원을 조정할 수 있습니다.\n",
      "  --num_layers NUM_LAYERS\n",
      "                        에서 Cross Network의 레이어 수를 조정할 수 있습니다.\n",
      "  --cnn_embed_dim CNN_EMBED_DIM\n",
      "                        CNN_FM에서 user와 item에 대한 embedding시킬 차원을 조정할 수 있습니다.\n",
      "  --cnn_latent_dim CNN_LATENT_DIM\n",
      "                        CNN_FM에서 user/item/image에 대한 latent 차원을 조정할 수 있습니다.\n",
      "  --vector_create VECTOR_CREATE\n",
      "                        DEEP_CONN에서 text vector 생성 여부를 조정할 수 있으며 최초 학습에만 True로\n",
      "                        설정하여야합니다.\n",
      "  --deepconn_embed_dim DEEPCONN_EMBED_DIM\n",
      "                        DEEP_CONN에서 user와 item에 대한 embedding시킬 차원을 조정할 수 있습니다.\n",
      "  --deepconn_latent_dim DEEPCONN_LATENT_DIM\n",
      "                        DEEP_CONN에서 user/item/image에 대한 latent 차원을 조정할 수 있습니다.\n",
      "  --conv_1d_out_dim CONV_1D_OUT_DIM\n",
      "                        DEEP_CONN에서 1D conv의 출력 크기를 조정할 수 있습니다.\n",
      "  --kernel_size KERNEL_SIZE\n",
      "                        DEEP_CONN에서 1D conv의 kernel 크기를 조정할 수 있습니다.\n",
      "  --word_dim WORD_DIM   DEEP_CONN에서 1D conv의 입력 크기를 조정할 수 있습니다.\n",
      "  --out_dim OUT_DIM     DEEP_CONN에서 1D conv의 출력 크기를 조정할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "!python main.py -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjw0112\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/data/ephemeral/Project/code/wandb/run-20231216_100929-7wce82ci\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmajor-planet-10\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/jw0112/Book_Recommendation\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/jw0112/Book_Recommendation/runs/7wce82ci\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n",
      "--------------- SDCN Load Data ---------------\n",
      "--------------- SDCN Train/Valid Split ---------------\n",
      "--------------- INIT SDCN ---------------\n",
      "--------------- SDCN TRAINING ---------------\n",
      "  0%|                                                   | 0/100 [00:00<?, ?it/s] Epoch : 1, Train Loss : 5.188, Valid Loss : 13.197, LR : 1e-05, EarlyStop Count : 0\n",
      "  1%|▍                                          | 1/100 [00:07<11:48,  7.15s/it] Epoch : 2, Train Loss : 3.432, Valid Loss : 2.340, LR : 1e-05, EarlyStop Count : 0\n",
      "  2%|▊                                          | 2/100 [00:13<11:08,  6.82s/it] Epoch : 3, Train Loss : 3.270, Valid Loss : 2.598, LR : 1e-05, EarlyStop Count : 1\n",
      "  3%|█▎                                         | 3/100 [00:20<10:51,  6.72s/it] Epoch : 4, Train Loss : 3.098, Valid Loss : 2.677, LR : 1e-05, EarlyStop Count : 2\n",
      "  4%|█▋                                         | 4/100 [00:26<10:29,  6.56s/it] Epoch : 5, Train Loss : 2.887, Valid Loss : 2.807, LR : 1e-05, EarlyStop Count : 3\n",
      "  5%|██▏                                        | 5/100 [00:33<10:18,  6.51s/it] Epoch : 6, Train Loss : 2.771, Valid Loss : 2.580, LR : 1e-05, EarlyStop Count : 4\n",
      "  6%|██▌                                        | 6/100 [00:39<10:14,  6.54s/it] Epoch : 7, Train Loss : 2.680, Valid Loss : 2.572, LR : 1e-05, EarlyStop Count : 5\n",
      "  7%|███                                        | 7/100 [00:46<10:08,  6.55s/it] Epoch : 8, Train Loss : 2.627, Valid Loss : 2.361, LR : 1e-05, EarlyStop Count : 6\n",
      "  8%|███▍                                       | 8/100 [00:52<09:57,  6.50s/it] Epoch : 9, Train Loss : 2.589, Valid Loss : 2.471, LR : 1e-05, EarlyStop Count : 7\n",
      "  9%|███▊                                       | 9/100 [00:59<09:51,  6.50s/it] Epoch : 10, Train Loss : 2.565, Valid Loss : 2.502, LR : 1e-05, EarlyStop Count : 8\n",
      " 10%|████▏                                     | 10/100 [01:05<09:40,  6.45s/it] Epoch : 11, Train Loss : 2.535, Valid Loss : 2.424, LR : 1e-05, EarlyStop Count : 9\n",
      " 11%|████▌                                     | 11/100 [01:12<09:36,  6.48s/it] Epoch : 12, Train Loss : 2.511, Valid Loss : 2.454, LR : 1e-05, EarlyStop Count : 10\n",
      " Early Stopping. Best Valid_loss : 2.340\n",
      " 11%|████▌                                     | 11/100 [01:18<10:34,  7.13s/it]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  Best Loss █▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Train Loss █▃▃▃▂▂▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Valid Loss █▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  Best Loss 2.34013\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Train Loss 2.51118\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Valid Loss 2.45447\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mmajor-planet-10\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/jw0112/Book_Recommendation/runs/7wce82ci\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ️⚡ View job at \u001b[34m\u001b[4mhttps://wandb.ai/jw0112/Book_Recommendation/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEyMzk2MzYzOA==/version_details/v0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20231216_100929-7wce82ci/logs\u001b[0m\n",
      "--------------- SDCN PREDICT ---------------\n",
      "--------------- SAVE SDCN PREDICT ---------------\n"
     ]
    }
   ],
   "source": [
    "!python main.py --model SDCN --runname SDCN_Epoch100_Layer5 --epoch 100 --num_layers 5 --patience 10 --lr 1e-5 --dropout 0.5 --batch_size 256 --lr_scheduler CosineAnnealingWarmRestarts --device cuda"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
