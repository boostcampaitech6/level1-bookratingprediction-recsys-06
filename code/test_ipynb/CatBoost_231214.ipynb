{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - defaults\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!conda install pytorch catboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False 0\n",
      "/data/ephemeral/home/level1-bookratingprediction-recsys-06/code/test_ipynb\n",
      "CatBoost Version : 1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ephemeral/home/miniconda3/envs/p1/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "print(torch.cuda.is_available(), torch.cuda.device_count())\n",
    "print(os.getcwd())\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import catboost\n",
    "from catboost import CatBoostRegressor\n",
    "print(f'CatBoost Version : {catboost.__version__}')\n",
    "\n",
    "import optuna\n",
    "from optuna import Trial, visualization\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "# 경고 메시지 숨기기\n",
    "import warnings\n",
    "warnings.filterwarnings(action = 'ignore')\n",
    "\n",
    "# Seed 고정\n",
    "SEED = 42\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    # tf.random.set_seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.use_deterministic_algorithms(False) # True\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![data](./code/data/Data_Schema.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = pd.read_csv('./code/data/books.csv')\n",
    "users = pd.read_csv('./code/data/users.csv')\n",
    "rating_train = pd.read_csv('./code/data/train_ratings.csv')\n",
    "rating_test = pd.read_csv('./code/data/test_ratings.csv')\n",
    "print(books.shape, users.shape, rating_train.shape, rating_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `books`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `isbn`\n",
    "    - https://sciencing.com/difference-isbn-13-isbn-10-5890031.html\n",
    "    - group identifier / publisher identifier / title identifier / and check digit로 구성\n",
    "    - Format : X-XXX-XXXXX-X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **ISBN 확인**\n",
    "- URL 정보를 사용해서 ISBN이 재대로 입력됐는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books['img_url_isbn'] = books['img_url'].apply(lambda x : x.split('/')[5].split('.')[0])\n",
    "books[books['isbn'] != books['img_url_isbn']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.drop(columns = 'img_url_isbn', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `book_author` 결측치 확인\n",
    "    - 실제 저자가 없는 책\n",
    "    - 동일한 `book_title`의 데이터도 없음\n",
    "    - => 동일한 `publisher`의 최빈값으로 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books[books['book_title'] == books.loc[books['book_author'].isna(), 'book_title'].values[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.loc[books['book_title'] == books.loc[books['book_author'].isna(), 'book_title'].values[0], 'book_author'] = \\\n",
    "    books.loc[books['publisher'] == books.loc[books['book_author'].isna(), 'publisher'].values[0], 'book_author'].mode().values[0]\n",
    "print(books['book_author'].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `year_of_publication`\n",
    "    - 10년 단위로 범주화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_year(x) :\n",
    "    if x < 1970 :\n",
    "        return 1970\n",
    "    elif (x >= 1970) and (x < 1980) :\n",
    "        return 1980\n",
    "    elif (x >= 1980) and (x < 1990) :\n",
    "        return 1990\n",
    "    elif (x >= 1990) and (x < 2000) :\n",
    "        return 2000\n",
    "    else :\n",
    "        return 2010\n",
    "    \n",
    "books['years'] = books['year_of_publication'].apply(preprocess_year)\n",
    "books['years'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `publisher`\n",
    "    - `isbn`의 앞 4개의 숫자를 활용하여 `new_publisher` 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publisher_dict = (books['publisher'].value_counts()).to_dict()\n",
    "publisher_count_df = pd.DataFrame(list(publisher_dict.items()), columns = ['publisher', 'count'])\n",
    "\n",
    "publisher_count_df = publisher_count_df.sort_values(by = ['count'], ascending = False)\n",
    "display(publisher_count_df.head(), books['publisher'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modify_list = publisher_count_df[publisher_count_df['count'] > 1]['publisher'].values\n",
    "\n",
    "for publisher in tqdm.tqdm(modify_list) :\n",
    "    try :\n",
    "        number = books[books['publisher'] == publisher]['isbn'].apply(lambda x : x[:4]).value_counts().index[0]\n",
    "        right_publisher = books[books['isbn'].apply(lambda x : x[:4]) == number]['publisher'].value_counts().index[0]\n",
    "        books.loc[books[books['isbn'].apply(lambda x : x[:4]) == number].index, 'new_publisher'] = right_publisher\n",
    "    except :\n",
    "        pass\n",
    "    \n",
    "print(books['new_publisher'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_publisher = books['new_publisher']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books['new_publisher'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `language`, `category`, `summary`\n",
    "    - `language` & `category` & `summary`가 모두 결측인 행 -> 67227행\n",
    "    - `language` & `summary`만 결측인 행 -> 67227 + 1624행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(books.loc[books['language'].isna(), ['language', 'category', 'summary']])\n",
    "display(books.loc[books['language'].isna() & books['category'].notnull()])\n",
    "display(books.loc[books['language'].isna() & books['summary'].notnull()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `language`는 `isbn`의 region 정보를 활용하여 결측치 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_code = set([code[:1] for code in books['isbn']])\n",
    "\n",
    "region_lang = dict()\n",
    "\n",
    "for code in region_code :\n",
    "    lang = books.loc[books['isbn'].str.startswith(str(code)), 'language']\n",
    "    mode = lang.mode()[0] if not code == 'B' else 'en' # 'B'로 시작하는 행들은 모두 NaN여서, 'en'으로 대체\n",
    "    books.loc[(books['isbn'].str.startswith(str(code))) & (books['language'].isna()), 'language'] = mode\n",
    "\n",
    "books['language'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `category`\n",
    "    - 상위 카테고리인 `category_high`를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대괄호 삭제\n",
    "books['category'] = books['category'].apply(lambda x : re.sub('[\\W_]+',  ' ', str(x).lower()).strip())\n",
    "\n",
    "category_df = pd.DataFrame(books['category'].value_counts()).reset_index()\n",
    "category_df.columns = ['category', 'count']\n",
    "category_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books['category_high'] = books['category'].copy()\n",
    "\n",
    "categories = ['garden', 'crafts', 'physics', 'adventure', 'music', 'fiction', 'nonfiction', 'science', 'science fiction', 'social', 'homicide', \n",
    "              'sociology', 'disease', 'religion', 'christian', 'philosophy', 'psycholog', 'mathemat', 'agricult', 'environmental',\n",
    "              'business', 'poetry', 'drama', 'literary', 'travel', 'motion picture', 'children', 'cook', 'literature', 'electronic', \n",
    "              'humor', 'animal', 'bird', 'photograph', 'computer', 'house', 'ecology', 'family', 'architect', 'camp', 'criminal', 'language', 'india']\n",
    "\n",
    "for category in categories :\n",
    "    books.loc[books[books['category'].str.contains(category, na = False)].index, 'category_high'] = category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_high_df = pd.DataFrame(books['category_high'].value_counts()).reset_index()\n",
    "category_high_df.columns = ['category', 'count']\n",
    "category_high_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5개 이하인 항목은 others\n",
    "others_list = category_high_df[category_high_df['count'] < 5]['category'].values\n",
    "print(len(others_list))\n",
    "\n",
    "books.loc[books[books['category_high'].isin(others_list)].index, 'category_high'] = 'others'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books['category_high'] = books['category_high'].replace('nan', np.nan)\n",
    "books['category_high'] = books['category_high'].replace('unknown', np.nan)\n",
    "print(books['category_high'].isna().sum())\n",
    "\n",
    "books['category_high'].fillna('fiction', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.to_csv('./code/data/books_preprocessed.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `users`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `location`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users['location'] = users['location'].str.replace(r'[^a-zA-Z:,]', '', regex = True)\n",
    "\n",
    "users['city'] = users['location'].apply(lambda x : x.split(',')[0].strip())\n",
    "users['state'] = users['location'].apply(lambda x : x.split(',')[1].strip())\n",
    "users['country'] = users['location'].apply(lambda x : x.split(',')[2].strip())\n",
    "\n",
    "users = users.replace('na', np.nan)\n",
    "users = users.replace('', np.nan) # 일부 경우 , , ,으로 입력된 경우가 있었으므로 이런 경우에도 결측값으로 변환합니다.\n",
    "\n",
    "users[['location', 'city', 'state', 'country']].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `city`가 가장 결측치가 적지만, 고윳값이 많아서 모델링할 때 그닥 좋은 성능을 낼 것 같지 않아보임\n",
    "    - `country`의 결측치를 채워서 분석에 사용하는 쪽으로 방향을 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(users['city'].nunique(), users['state'].nunique(), users['country'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# country가 결측 / state 결측 X인 경우\n",
    "states = users[(users['state'].notnull()) & (users['country'].isna())]['state'].values\n",
    "\n",
    "for state in tqdm.tqdm(states) :\n",
    "    try :\n",
    "        country = users.loc[(users['location'].str.contains(state)), 'country'].value_counts().index[0]\n",
    "        users.loc[(users['location'].str.contains(state)) & (users['country'].isna()), 'country'] = country\n",
    "    except :\n",
    "        pass\n",
    "\n",
    "# country가 결측 / city 결측 X인 경우\n",
    "cities = users[(users['city'].notnull()) & (users['country'].isna())]['city'].values\n",
    "\n",
    "for city in tqdm.tqdm(cities) :\n",
    "    try :\n",
    "        country = users.loc[(users['location'].str.contains(city)), 'country'].value_counts().index[0]\n",
    "        users.loc[(users['location'].str.contains(city)) & (users['country'].isna()), 'country'] = country\n",
    "    except :\n",
    "        pass\n",
    "\n",
    "# 각 나라 별로 location의 최빈값으로 대체\n",
    "countries_list = users['country'].value_counts()\n",
    "for country in tqdm.tqdm(countries_list.index) :\n",
    "    try :\n",
    "        new_country = users.loc[(users['location'].str.contains(country)), 'country'].value_counts().index[0]\n",
    "        users.loc[(users['location'].str.contains(country)) & (users['country'] == country), \n",
    "                  'country'] = new_country\n",
    "    except :\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(users['country'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `country`의 오타나 오기입되어 있는 값 처리\n",
    "- canada -> 'canada', 'cananda', 'vvh', 'lkjlj'\n",
    "- italy -> 'italia', 'italy', 'litalia', 'ineurope'\n",
    "- phillipines -> 'phillipines', 'phillippines'\n",
    "- spain -> 'catalunyaspain', 'spain'\n",
    "- unitedkingdom -> 'unitedkingdom', 'usacurrentlylivinginengland', 'unitedkindgonm', 'obviously'\n",
    "- usa -> 'unitedstates', 'unitedstaes', 'unitedstatesofamerica', 'usa', 'usanow', 'ysa', 'csa', 'anystate', 'usacanada'\n",
    "- uruguay -> 'urugua', 'uruguay'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Before : {users[\"country\"].nunique()}')\n",
    "country_mapping = {\n",
    "    'canada': ['canada', 'cananda', 'vvh', 'lkjlj'],\n",
    "    'italy': ['italia', 'italy', 'litalia', 'ineurope'],\n",
    "    'phillipines': ['phillipines', 'phillippines'],\n",
    "    'spain': ['catalunyaspain', 'spain'],\n",
    "    'unitedkingdom': ['unitedkingdom', 'usacurrentlylivinginengland', 'unitedkindgonm', 'obviously'],\n",
    "    'usa': ['unitedstates', 'unitedstaes', 'unitedsates', 'unitedstatesofamerica', 'usa', 'usanow', 'ysa', 'csa', 'anystate', 'usacanada'],\n",
    "    'uruguay': ['urugua', 'uruguay']\n",
    "}\n",
    "\n",
    "for target_country, aliases in country_mapping.items() :\n",
    "    users['country'].replace(aliases, target_country, inplace = True)\n",
    "\n",
    "print(f'After : {users[\"country\"].nunique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(users['country'].isna().sum())\n",
    "users['country'].value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10개 이하의 country를 others로 변환\n",
    "others = users['country'].value_counts()[users['country'].value_counts() < 10].index\n",
    "for country in tqdm.tqdm(others) :\n",
    "    try :\n",
    "        users.loc[(users['country'] == country), 'country'] = 'others'\n",
    "    except :\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 나머지 결측치에 대해서도 others로 변환\n",
    "users['country'] = users['country'].fillna('others')\n",
    "print(users['country'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `age`\n",
    "    - 국가별 `age`의 중앙값으로 대체\n",
    "    - 국가별 `age`의 중앙값이 존재하지 않는 경우, 전체 `age`의 중앙값으로 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_age_median = users.groupby('country')['age'].median()\n",
    "users['age'] = users.apply(lambda x : country_age_median[x['country']] if pd.isna(x['age']) else x['age'], axis = 1)\n",
    "\n",
    "global_age_median = users['age'].median()\n",
    "users['age'].fillna(global_age_median, inplace = True)\n",
    "print(users['age'].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 10살 단위 연령대로 분할하여 `new_age` 변수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users['new_age'] = ((users['age'] // 10) * 10).astype(int)\n",
    "users[['age', 'new_age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.to_csv('./code/data/users_preprocessed.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `ratings`와 Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './code/data/'\n",
    "books_pre = pd.read_csv(path + 'books_preprocessed.csv')\n",
    "users_pre = pd.read_csv(path + 'users_preprocessed.csv')\n",
    "train_ratings = pd.read_csv(path + 'train_ratings.csv')\n",
    "test_ratings = pd.read_csv(path + 'test_ratings.csv')\n",
    "\n",
    "print(books_pre.shape, users_pre.shape, train_ratings.shape, test_ratings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(books_pre.info(), users_pre.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_final = books_pre[['isbn', 'language', 'years', 'new_publisher', 'category_high']]\n",
    "users_final = users_pre[['user_id', 'country', 'new_age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratings['index'] = train_ratings.index\n",
    "train_df = pd.merge(books_final, train_ratings, how = 'left', on = 'isbn').dropna(subset = 'rating')\n",
    "train_df = pd.merge(users_final, train_df, how = 'left', on = 'user_id').dropna(subset = 'rating')\n",
    "train_df = train_df.sort_values('index').reset_index(drop = True).drop(columns = 'index')\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratings['index'] = test_ratings.index\n",
    "test_df = pd.merge(books_final, test_ratings, how = 'left', on = 'isbn').dropna(subset = 'rating')\n",
    "test_df = pd.merge(users_final, test_df, how = 'left', on = 'user_id').dropna(subset = 'rating')\n",
    "test_df = test_df.sort_values('index').reset_index(drop = True).drop(columns = 'index')\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `avg_rating`\n",
    "    - `user_id`별 평균 `rating`의 값을 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_rating = train_df.groupby('user_id', as_index = False)['rating'].mean().rename({'rating' : 'avg_rating'}, axis = 1)\n",
    "train_df = pd.merge(train_df, avg_rating, how = 'left', on = 'user_id')\n",
    "test_df = pd.merge(test_df, avg_rating, how = 'left', on = 'user_id')\n",
    "test_df['avg_rating'].fillna(train_df['rating'].mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['user_id'] = train_df['user_id'].astype('str')\n",
    "train_df['new_age'] = train_df['new_age'].astype('category')\n",
    "train_df['years'] = train_df['years'].astype('int').astype('category')\n",
    "train_df['rating'] = train_df['rating'].astype('int')\n",
    "\n",
    "test_df['user_id'] = test_df['user_id'].astype('str')\n",
    "test_df['new_age'] = test_df['new_age'].astype('category')\n",
    "test_df['years'] = test_df['years'].astype('int').astype('category')\n",
    "test_df['rating'] = test_df['rating'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train_df.drop(columns = 'rating'), train_df['rating'],\n",
    "                                                      test_size = 0.2, random_state = SEED)\n",
    "print(X_train.shape, y_train.shape, X_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.integration import CatBoostPruningCallback\n",
    "\n",
    "def objectiveCAT(trial : Trial, X_train, y_train, X_valid, y_valid) :\n",
    "    param = {\n",
    "        'learning_rate' : trial.suggest_categorical('learning_rate', [1e-3, 0.01, 0.1, 0.5]),\n",
    "        'depth' : trial.suggest_int('depth', 1, 15),\n",
    "        'colsample_bylevel' : trial.suggest_categorical('colsample_bylevel', [1e-3, 0.01, 0.1, 0.5]),   \n",
    "        'boosting_type' : trial.suggest_categorical('boosting_type', ['Ordered', 'Plain']),\n",
    "        'bootstrap_type' : trial.suggest_categorical('bootstrap_type', ['Bayesian', 'Bernoulli', 'MVS']),\n",
    "    }\n",
    "\n",
    "    if param['bootstrap_type'] == 'Bayesian':\n",
    "        param['bagging_temperature'] = trial.suggest_float('bagging_temperature', 0, 10)\n",
    "    elif param['bootstrap_type'] == 'Bernoulli':\n",
    "        param['subsample'] = trial.suggest_float('subsample', 0.1, 1)\n",
    "        \n",
    "    model = CatBoostRegressor(**param, loss_function = 'RMSE', eval_metric = 'RMSE',\n",
    "                              use_best_model = True, random_state = SEED, # task_type = 'GPU', devices = '0'\n",
    "                              cat_features = [0, 1, 2, 3, 4, 5, 6, 7])\n",
    "    pruning_callback = CatBoostPruningCallback(trial, 'RMSE', eval_set_index = 1)\n",
    "    cat_model = model.fit(X_train, y_train, eval_set = [(X_train, y_train), (X_valid, y_valid)], verbose = False,\n",
    "                          early_stopping_rounds = 100, callbacks = [pruning_callback])\n",
    "    pruning_callback.check_pruned()\n",
    "    \n",
    "    score = mean_squared_error(y_valid, cat_model.predict(X_valid), squared = False)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Study Optuna\n",
    "study = optuna.create_study(direction = 'minimize', sampler = TPESampler(seed = SEED))\n",
    "study.optimize(lambda trial : objectiveCAT(trial, X_train, y_train, X_valid, y_valid), n_trials = 30)\n",
    "print(f'Best trial : score {study.best_trial.value}, \\n params = {study.best_trial.params} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'learning_rate': 0.1, 'depth': 10, 'colsample_bylevel': 0.5, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data, y_data = train_df.drop(columns = 'rating'), train_df['rating']\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = SEED)\n",
    "valid_rmse = []\n",
    "\n",
    "# Stratified K-Fold 사용하여 Best Parameter 학습\n",
    "for fold, (train_idx, valid_idx) in tqdm.tqdm(enumerate(skf.split(X_data, y_data)), total = skf.n_splits) :\n",
    "    \n",
    "    # Train Set과 Valid Set 분할    \n",
    "    X_train, y_train = X_data.iloc[train_idx], y_data.iloc[train_idx]\n",
    "    X_valid, y_valid = X_data.iloc[valid_idx], y_data.iloc[valid_idx]\n",
    "    \n",
    "    # Best Parameter 학습\n",
    "    param = best_params # study.best_params\n",
    "    \n",
    "    cat_reg = CatBoostRegressor(**param, loss_function = 'RMSE', eval_metric = 'RMSE', \n",
    "                                use_best_model = True, random_state = SEED,\n",
    "                                cat_features = [0, 1, 2, 3, 4, 5, 6, 7])\n",
    "    cat_reg.fit(X_train, y_train, eval_set = [(X_train, y_train), (X_valid, y_valid)],\n",
    "                verbose = 300, early_stopping_rounds = 100)\n",
    "    \n",
    "    # 모델 RMSE 출력\n",
    "    score = mean_squared_error(y_valid, cat_reg.predict(X_valid), squared = False)\n",
    "    valid_rmse.append(score)\n",
    "    print(f'Valid Set {fold + 1} 번째 Fold RMSE : {score}')\n",
    "\n",
    "\n",
    "print(f'모델 RMSE 평균 : {np.array(valid_rmse).mean()} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = cat_reg.feature_importances_\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "fig = plt.figure(figsize = (12, 6))\n",
    "plt.barh(range(len(sorted_idx)), feature_importance[sorted_idx], align = 'center')\n",
    "plt.yticks(range(len(sorted_idx)), np.array(X_data.columns)[sorted_idx])\n",
    "plt.title('Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = cat_reg.predict(test_df.drop(columns = 'rating'))\n",
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['rating'] = test_pred.round().astype('int')\n",
    "submit = test_df[['user_id', 'isbn', 'rating']]\n",
    "submit.to_csv('./code/submit/Catboost_Optuna.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
